#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¹¶å‘åŒæ­¥æ§åˆ¶æµ‹è¯•è„šæœ¬
æµ‹è¯•å¤šè¿›ç¨‹åŒæ­¥çš„å®‰å…¨æ€§å’Œé”æœºåˆ¶çš„æœ‰æ•ˆæ€§
"""

import os
import sys
import time
import multiprocessing
import tempfile
import shutil
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from sync_lock_manager import SyncLockManager
from media_sync import MediaSyncManager
from config_manager import ConfigManager

class ConcurrencyTester:
    """å¹¶å‘æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.test_dir = None
        self.lock_manager = None
        self.results = []
        
    def setup_test_environment(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        # åˆ›å»ºä¸´æ—¶æµ‹è¯•ç›®å½•
        self.test_dir = tempfile.mkdtemp(prefix='concurrency_test_')
        print(f"æµ‹è¯•ç›®å½•: {self.test_dir}")
        
        # åˆ›å»ºé”ç®¡ç†å™¨
        lock_dir = os.path.join(self.test_dir, 'locks')
        os.makedirs(lock_dir, exist_ok=True)
        self.lock_manager = SyncLockManager(lock_dir=lock_dir, lock_timeout=60)
        
        # åˆ›å»ºæµ‹è¯•åª’ä½“ç›®å½•
        media_dir = os.path.join(self.test_dir, 'media')
        os.makedirs(media_dir, exist_ok=True)
        
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        for i in range(3):
            test_file = os.path.join(media_dir, f'test_video_{i}.mp4')
            with open(test_file, 'wb') as f:
                f.write(b'test video content ' * 100)  # åˆ›å»ºä¸€äº›æµ‹è¯•å†…å®¹
        
        return media_dir
    
    def cleanup_test_environment(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        if self.test_dir and os.path.exists(self.test_dir):
            shutil.rmtree(self.test_dir)
            print(f"æµ‹è¯•ç¯å¢ƒå·²æ¸…ç†: {self.test_dir}")
    
    def simulate_sync_process(self, process_id: int, media_dir: str, duration: int = 5):
        """æ¨¡æ‹ŸåŒæ­¥è¿›ç¨‹
        
        Args:
            process_id: è¿›ç¨‹ID
            media_dir: åª’ä½“ç›®å½•
            duration: æ¨¡æ‹Ÿå·¥ä½œæ—¶é•¿ï¼ˆç§’ï¼‰
        
        Returns:
            è¿›ç¨‹æ‰§è¡Œç»“æœ
        """
        try:
            start_time = time.time()
            
            # æ¯ä¸ªè¿›ç¨‹åˆ›å»ºè‡ªå·±çš„é”ç®¡ç†å™¨å®ä¾‹ï¼Œä½†ä½¿ç”¨ç›¸åŒçš„é”ç›®å½•
            lock_dir = os.path.join(os.path.dirname(media_dir), 'locks')
            lock_manager = SyncLockManager(lock_dir=lock_dir, lock_timeout=60)
            
            # å°è¯•è·å–åŒæ­¥é”
            with lock_manager.sync_lock(timeout=30) as lock_acquired:
                if not lock_acquired:
                    return {
                        'process_id': process_id,
                        'status': 'failed',
                        'reason': 'failed_to_acquire_lock',
                        'start_time': start_time,
                        'end_time': time.time(),
                        'duration': time.time() - start_time
                    }
                
                # æ¨¡æ‹ŸåŒæ­¥å·¥ä½œ
                work_start = time.time()
                print(f"è¿›ç¨‹ {process_id}: å¼€å§‹åŒæ­¥å·¥ä½œ ({datetime.now().strftime('%H:%M:%S')})")
                
                # æ¨¡æ‹Ÿæ–‡ä»¶å¤„ç†
                files = [f for f in os.listdir(media_dir) if f.endswith('.mp4')]
                for i, filename in enumerate(files):
                    time.sleep(duration / len(files))  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                    print(f"è¿›ç¨‹ {process_id}: å¤„ç†æ–‡ä»¶ {filename} ({i+1}/{len(files)})")
                
                work_end = time.time()
                print(f"è¿›ç¨‹ {process_id}: åŒæ­¥å·¥ä½œå®Œæˆ ({datetime.now().strftime('%H:%M:%S')})")
                
                return {
                    'process_id': process_id,
                    'status': 'success',
                    'reason': 'completed_successfully',
                    'start_time': start_time,
                    'work_start': work_start,
                    'work_end': work_end,
                    'end_time': time.time(),
                    'duration': time.time() - start_time,
                    'work_duration': work_end - work_start,
                    'files_processed': len(files)
                }
                
        except Exception as e:
            return {
                'process_id': process_id,
                'status': 'error',
                'reason': str(e),
                'start_time': start_time,
                'end_time': time.time(),
                'duration': time.time() - start_time
            }
    
    def test_concurrent_sync(self, num_processes: int = 3, work_duration: int = 3):
        """æµ‹è¯•å¹¶å‘åŒæ­¥
        
        Args:
            num_processes: å¹¶å‘è¿›ç¨‹æ•°
            work_duration: æ¯ä¸ªè¿›ç¨‹çš„å·¥ä½œæ—¶é•¿
        """
        print(f"\n=== æµ‹è¯•å¹¶å‘åŒæ­¥æ§åˆ¶ ({num_processes} ä¸ªè¿›ç¨‹) ===")
        
        media_dir = self.setup_test_environment()
        
        try:
            # åˆ›å»ºè¿›ç¨‹æ± 
            with multiprocessing.Pool(processes=num_processes) as pool:
                # å¯åŠ¨å¤šä¸ªåŒæ­¥è¿›ç¨‹
                print(f"å¯åŠ¨ {num_processes} ä¸ªå¹¶å‘åŒæ­¥è¿›ç¨‹...")
                
                # ä½¿ç”¨å¼‚æ­¥æ–¹å¼å¯åŠ¨è¿›ç¨‹
                async_results = []
                for i in range(num_processes):
                    result = pool.apply_async(
                        self.simulate_sync_process,
                        args=(i + 1, media_dir, work_duration)
                    )
                    async_results.append(result)
                    time.sleep(0.1)  # ç¨å¾®é”™å¼€å¯åŠ¨æ—¶é—´
                
                # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
                results = []
                for async_result in async_results:
                    try:
                        result = async_result.get(timeout=60)  # æœ€å¤šç­‰å¾…60ç§’
                        results.append(result)
                    except multiprocessing.TimeoutError:
                        results.append({
                            'process_id': 'unknown',
                            'status': 'timeout',
                            'reason': 'process_timeout'
                        })
            
            # åˆ†æç»“æœ
            self.analyze_concurrency_results(results)
            
        finally:
            self.cleanup_test_environment()
    
    def analyze_concurrency_results(self, results):
        """åˆ†æå¹¶å‘æµ‹è¯•ç»“æœ
        
        Args:
            results: è¿›ç¨‹æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        print("\n=== å¹¶å‘æµ‹è¯•ç»“æœåˆ†æ ===")
        
        successful_processes = [r for r in results if r['status'] == 'success']
        failed_processes = [r for r in results if r['status'] == 'failed']
        error_processes = [r for r in results if r['status'] == 'error']
        timeout_processes = [r for r in results if r['status'] == 'timeout']
        
        print(f"æ€»è¿›ç¨‹æ•°: {len(results)}")
        print(f"æˆåŠŸå®Œæˆ: {len(successful_processes)}")
        print(f"è·å–é”å¤±è´¥: {len(failed_processes)}")
        print(f"æ‰§è¡Œé”™è¯¯: {len(error_processes)}")
        print(f"è¶…æ—¶: {len(timeout_processes)}")
        
        # è¯¦ç»†ç»“æœ
        print("\nè¯¦ç»†ç»“æœ:")
        for result in results:
            process_id = result['process_id']
            status = result['status']
            reason = result.get('reason', 'unknown')
            duration = result.get('duration', 0)
            
            if status == 'success':
                work_duration = result.get('work_duration', 0)
                files_processed = result.get('files_processed', 0)
                print(f"  è¿›ç¨‹ {process_id}: âœ“ æˆåŠŸ (æ€»æ—¶é•¿: {duration:.2f}s, å·¥ä½œæ—¶é•¿: {work_duration:.2f}s, å¤„ç†æ–‡ä»¶: {files_processed})")
            elif status == 'failed':
                print(f"  è¿›ç¨‹ {process_id}: âœ— å¤±è´¥ - {reason} (æ—¶é•¿: {duration:.2f}s)")
            elif status == 'error':
                print(f"  è¿›ç¨‹ {process_id}: âš  é”™è¯¯ - {reason} (æ—¶é•¿: {duration:.2f}s)")
            else:
                print(f"  è¿›ç¨‹ {process_id}: ? {status} - {reason}")
        
        # éªŒè¯å¹¶å‘æ§åˆ¶
        print("\n=== å¹¶å‘æ§åˆ¶éªŒè¯ ===")
        
        if len(successful_processes) == 1:
            print("âœ“ å¹¶å‘æ§åˆ¶æ­£å¸¸ï¼šåªæœ‰ä¸€ä¸ªè¿›ç¨‹æˆåŠŸè·å–é”å¹¶å®ŒæˆåŒæ­¥")
        elif len(successful_processes) == 0:
            print("âš  è­¦å‘Šï¼šæ²¡æœ‰è¿›ç¨‹æˆåŠŸå®ŒæˆåŒæ­¥")
        else:
            print(f"âœ— å¹¶å‘æ§åˆ¶å¤±è´¥ï¼š{len(successful_processes)} ä¸ªè¿›ç¨‹åŒæ—¶è·å–äº†é”")
        
        if len(failed_processes) > 0:
            print(f"âœ“ é”æœºåˆ¶æ­£å¸¸ï¼š{len(failed_processes)} ä¸ªè¿›ç¨‹å› æ— æ³•è·å–é”è€Œè·³è¿‡")
        
        # æ—¶é—´é‡å æ£€æŸ¥
        if len(successful_processes) > 1:
            print("\næ£€æŸ¥æ—¶é—´é‡å :")
            for i, proc1 in enumerate(successful_processes):
                for proc2 in successful_processes[i+1:]:
                    if self.check_time_overlap(proc1, proc2):
                        print(f"âœ— å‘ç°æ—¶é—´é‡å ï¼šè¿›ç¨‹ {proc1['process_id']} å’Œè¿›ç¨‹ {proc2['process_id']}")
                    else:
                        print(f"âœ“ æ— æ—¶é—´é‡å ï¼šè¿›ç¨‹ {proc1['process_id']} å’Œè¿›ç¨‹ {proc2['process_id']}")
        
        # æ€»ç»“
        print("\n=== æµ‹è¯•æ€»ç»“ ===")
        if len(successful_processes) == 1 and len(failed_processes) > 0:
            print("ğŸ‰ å¹¶å‘æ§åˆ¶æµ‹è¯•é€šè¿‡ï¼")
            print("   - åªæœ‰ä¸€ä¸ªè¿›ç¨‹æˆåŠŸè·å–é”")
            print("   - å…¶ä»–è¿›ç¨‹æ­£ç¡®åœ°è¢«é˜»æ­¢")
            print("   - é”æœºåˆ¶å·¥ä½œæ­£å¸¸")
        else:
            print("âŒ å¹¶å‘æ§åˆ¶æµ‹è¯•å¤±è´¥ï¼")
            print("   - å¯èƒ½å­˜åœ¨é”æœºåˆ¶é—®é¢˜")
            print("   - éœ€è¦æ£€æŸ¥åŒæ­¥é”å®ç°")
    
    def check_time_overlap(self, proc1, proc2):
        """æ£€æŸ¥ä¸¤ä¸ªè¿›ç¨‹çš„å·¥ä½œæ—¶é—´æ˜¯å¦é‡å 
        
        Args:
            proc1: è¿›ç¨‹1ç»“æœ
            proc2: è¿›ç¨‹2ç»“æœ
            
        Returns:
            æ˜¯å¦å­˜åœ¨æ—¶é—´é‡å 
        """
        start1 = proc1.get('work_start', proc1.get('start_time', 0))
        end1 = proc1.get('work_end', proc1.get('end_time', 0))
        start2 = proc2.get('work_start', proc2.get('start_time', 0))
        end2 = proc2.get('work_end', proc2.get('end_time', 0))
        
        # æ£€æŸ¥æ—¶é—´åŒºé—´æ˜¯å¦é‡å 
        return not (end1 <= start2 or end2 <= start1)

def main():
    """ä¸»å‡½æ•°"""
    print("=== å¹¶å‘åŒæ­¥æ§åˆ¶æµ‹è¯• ===")
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    tester = ConcurrencyTester()
    
    try:
        # æµ‹è¯•ä¸åŒçš„å¹¶å‘åœºæ™¯
        test_scenarios = [
            {'processes': 2, 'duration': 2, 'name': 'è½»é‡å¹¶å‘æµ‹è¯•'},
            {'processes': 3, 'duration': 3, 'name': 'ä¸­ç­‰å¹¶å‘æµ‹è¯•'},
            {'processes': 5, 'duration': 2, 'name': 'é«˜å¹¶å‘æµ‹è¯•'}
        ]
        
        for scenario in test_scenarios:
            print(f"\n{'='*50}")
            print(f"åœºæ™¯: {scenario['name']}")
            print(f"è¿›ç¨‹æ•°: {scenario['processes']}, å·¥ä½œæ—¶é•¿: {scenario['duration']}ç§’")
            print(f"{'='*50}")
            
            tester.test_concurrent_sync(
                num_processes=scenario['processes'],
                work_duration=scenario['duration']
            )
            
            # åœºæ™¯é—´ç¨ä½œä¼‘æ¯
            time.sleep(1)
        
        print(f"\n=== æ‰€æœ‰å¹¶å‘æµ‹è¯•å®Œæˆ ===")
        print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
    except KeyboardInterrupt:
        print("\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\næµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    print("è„šæœ¬å¼€å§‹æ‰§è¡Œ...")
    # è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•
    try:
        multiprocessing.set_start_method('spawn', force=True)
        print("å¤šè¿›ç¨‹æ–¹æ³•è®¾ç½®å®Œæˆ")
    except RuntimeError:
        print("å¤šè¿›ç¨‹æ–¹æ³•å·²è®¾ç½®ï¼Œè·³è¿‡")
    
    print("è°ƒç”¨mainå‡½æ•°...")
    main()